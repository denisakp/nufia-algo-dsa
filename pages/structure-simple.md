# SÃ©quences - Arrays vs Linked Lists

## Arrays/Lists
- **Structure:** MÃ©moire contiguÃ«
- **AccÃ¨s:** O(1) par index
- **Insertion:** O(n) au milieu
- **Usage:** AccÃ¨s frÃ©quent par position
  
<br/>

## Linked Lists
- **Structure:** NÅ“uds + pointeurs
- **AccÃ¨s:** O(n) sÃ©quentiel
- **Insertion:** O(1) si position connue
- **Usage:** Insertions/suppressions frÃ©quentes

ğŸ’¡ **DÃ©mo Live:** Mesure de performance avec timeit

ğŸ—ï¸ **La structure physique en mÃ©moire dicte les performances**

<!--
CommenÃ§ons par le plus fondamental : comment organiser une sÃ©quence d'Ã©lÃ©ments ?

[ARRAYS]
Arrays = mÃ©moire contiguÃ«. Imaginez des maisons numÃ©rotÃ©es dans une rue : pour aller Ã  la maison 10, vous calculez directement l'adresse. C'est O(1). Mais pour insÃ©rer une nouvelle maison au milieu ? Il faut dÃ©caler toutes les suivantes = O(n).

[LINKED LISTS]  
Linked Lists = comme un jeu de piste. Chaque nÅ“ud dit "le suivant est lÃ -bas". Pour accÃ©der au 10e Ã©lÃ©ment ? Suivez la chaÃ®ne = O(n). Mais pour insÃ©rer ? Changez juste 2 pointeurs = O(1).

[DÃ‰MO LIVE - si possible]
"Faisons un test rapide en Python :
- Array : accÃ¨s arr[1000] vs insertion arr.insert(500, x)
- LinkedList : accÃ¨s suivre 1000 liens vs insertion entre 2 nÅ“uds"

Le message clÃ© : LA STRUCTURE PHYSIQUE EN MÃ‰MOIRE dÃ©termine les performances. Arrays = accÃ¨s random rapide, Lists = modifications rapides. Votre choix dÃ©pend de votre usage dominant : vous accÃ©dez plus ou vous modifiez plus ?

Pour les seniors : c'est pourquoi Python utilise dynamic arrays (listes qui peuvent grandir) - compromis entre les deux !
-->

---

# Dictionnaires - La RÃ©volution O(1)

## Comment le Hachage Change Tout
- **Principe:** Transformer une clÃ© en adresse mÃ©moire directe
- **RÃ©sultat:** AccÃ¨s instantanÃ©, indÃ©pendant de la taille

<br>

## Cas d'Usage Transformateurs:
- **Comptage de frÃ©quences:** Counter en O(n) au lieu de O(nÂ²)
- **Recherche d'existence:** O(1) au lieu de O(n)
- **Index inversÃ©:** Moteurs de recherche
- **Cache/MÃ©moÃ¯sation:** Ã‰viter les recalculs

<br>

âš¡ **Une structure qui transforme O(n) en O(1) = RÃ©volution algorithmique**

<!--
Les dictionnaires/hash tables = LA rÃ©volution en informatique !

[PRINCIPE DE BASE]
Imaginez une bibliothÃ¨que oÃ¹ au lieu de chercher un livre rayon par rayon, vous avez une formule magique : "titre du livre" â†’ adresse exacte de l'Ã©tagÃ¨re. C'est le hachage : clÃ© â†’ adresse mÃ©moire directe.

[IMPACT TRANSFORMATEUR - exemples concrets]
- Compter les mots dans un texte : sans dict = comparer chaque mot Ã  tous les prÃ©cÃ©dents O(nÂ²), avec dict = un seul lookup O(1) par mot = O(n) total !
- "Est-ce que cet utilisateur existe ?" : sans dict = parcourir toute la liste, avec dict = lookup instantanÃ©
- Google : chercher "python" â†’ hash("python") â†’ liste instantanÃ©e des pages

[POUR LES JUNIORS]
Exemple pratique : vous avez une liste d'emails et vous voulez savoir si "john@email.com" est dedans. Sans dict : parcourir toute la liste. Avec dict : transformation en 0.0001 seconde !

[POUR LES SENIORS]  
C'est pourquoi Redis, les caches, les bases NoSQL sont si puissants. La structure hash table permet des algorithmes qui Ã©taient impensables avant.

Message clÃ© : une structure qui casse la barriÃ¨re O(n) et donne O(1) = c'est RÃ‰VOLUTIONNAIRE. Cela change complÃ¨tement quels algorithmes sont possibles !
-->

---
layout: two-cols-header
---

# LIFO/FIFO - Quand l'Ordre Dicte l'Algorithme

::left::

## ğŸ¥ Stacks (LIFO)
- **Structure:** Dernier entrÃ©, premier sorti
- **OpÃ©rations:** push(), pop()
- **Algorithmes naturels:**
  - Parcours DFS
  - Ã‰valuation d'expressions
  - Undo/Redo

::right::

## ğŸš¶â€â™‚ï¸ Queues (FIFO)
- **Structure:** Premier entrÃ©, premier sorti
- **OpÃ©rations:** enqueue(), dequeue()
- **Algorithmes naturels:**
  - Parcours BFS
  - Files d'attente
  - Traitement par lots

ğŸ”„ **La contrainte d'ordre de la structure gÃ©nÃ¨re naturellement l'algorithme**

<!--
Ici, la CONTRAINTE d'ordre de la structure dicte complÃ¨tement l'algorithme !

[STACKS - LIFO]
Stack = pile d'assiettes. La derniÃ¨re posÃ©e est la premiÃ¨re rÃ©cupÃ©rÃ©e. Cette contrainte simple gÃ©nÃ¨re des algorithmes puissants :
- DFS : on "empile" les voisins, on "dÃ©pile" le plus rÃ©cent â†’ exploration en profondeur naturelle
- Expressions : (2 + 3) * 4 â†’ on empile les opÃ©rateurs, on dÃ©pile dans l'ordre inverse
- Undo : chaque action empilÃ©e, undo dÃ©pile la plus rÃ©cente

[QUEUES - FIFO]  
Queue = file d'attente au supermarchÃ©. Premier arrivÃ©, premier servi. Cette contrainte gÃ©nÃ¨re d'autres algorithmes :
- BFS : on "enfile" les voisins, on "dÃ©file" le plus ancien â†’ exploration niveau par niveau
- Traitement : les requÃªtes arrivent, elles sont traitÃ©es dans l'ordre d'arrivÃ©e

[INSIGHT CRUCIAL]
Regardez la magie : mÃªme donnÃ©es (un graphe), mais structure diffÃ©rente (Stack vs Queue) = algorithme complÃ¨tement diffÃ©rent (DFS vs BFS) !

Pour les dÃ©butants : Stack = pile de livres, Queue = file d'attente
Pour les seniors : c'est pourquoi les architectures asynchrones utilisent des queues - l'ordre FIFO garantit la fairness du traitement

Message : la contrainte structurelle (LIFO vs FIFO) gÃ©nÃ¨re NATURELLEMENT l'algorithme optimal !
-->

---

# Arbres - Penser en HiÃ©rarchies

## Concepts Fondamentaux:
- **NÅ“uds:** Ã‰lÃ©ments de donnÃ©es
- **Relations:** Parent-enfant naturelles
- **Racine:** Point d'entrÃ©e unique
- **Feuilles:** NÅ“uds terminaux

<br>

## Applications ConcrÃ¨tes:
- **DOM HTML:** Structure hiÃ©rarchique des pages web
- **SystÃ¨me de fichiers:** Dossiers et sous-dossiers
- **Arbres de dÃ©cision:** Intelligence artificielle
- **Taxonomies:** Classifications biologiques

ğŸŒ³ **Les relations hiÃ©rarchiques naturelles des donnÃ©es suggÃ¨rent la structure arbre**

<!--
Les arbres = quand vos donnÃ©es ont des relations hiÃ©rarchiques naturelles !

[POURQUOI DES ARBRES ?]
Certaines donnÃ©es sont NATURELLEMENT hiÃ©rarchiques. Forcer une hiÃ©rarchie dans une liste = complexitÃ© artificielle. Accepter la hiÃ©rarchie avec un arbre = simplicitÃ© naturelle.

[EXEMPLES CONCRETS]
- HTML DOM : <html> contient <body>, <body> contient <div>, etc. â†’ structure arbre parfaite
- Fichiers : Dossier "Photos" contient "Vacances", "Vacances" contient "plage.jpg" â†’ arbre naturel
- Entreprise : CEO â†’ Directeurs â†’ Managers â†’ EmployÃ©s â†’ hiÃ©rarchie = arbre
- IA : "Animal ?" â†’ "MammifÃ¨re ?" â†’ "Carnivore ?" â†’ "Chat !" â†’ arbre de dÃ©cision

[INSIGHT FONDAMENTAL]
Ne FORCEZ pas des donnÃ©es hiÃ©rarchiques dans des structures plates ! Si vous avez des relations parent-enfant, utilisez un arbre. L'algorithme de navigation devient trivial : rÃ©cursion naturelle.

Pour les dÃ©butants : pensez arbre gÃ©nÃ©alogique - relations parent-enfant Ã©videntes
Pour les seniors : c'est pourquoi React utilise un Virtual DOM tree, les parsers crÃ©ent des AST trees - la structure reflÃ¨te parfaitement le problÃ¨me

Message : quand vos donnÃ©es sont hiÃ©rarchiques, la structure arbre rend les algorithmes Ã©vidents !
-->

---

# Binary Search Trees - Structure qui Garantit l'EfficacitÃ©

## PropriÃ©tÃ© Fondamentale:
- **RÃ¨gle:** Gauche < Racine < Droite
- **ConsÃ©quence:** Recherche en O(log n) automatique

<br>

## Parcours Naturels:
- **In-order:** Gauche â†’ Racine â†’ Droite = **Tri automatique !**
- **Pre-order:** Racine â†’ Gauche â†’ Droite
- **Post-order:** Gauche â†’ Droite â†’ Racine

<br>

ğŸ’¡ **Insight clÃ©:** La structure impose l'ordre, l'algorithme de tri devient trivial !

ğŸ¯ **Une contrainte structurelle simple = algorithmes complexes rendus Ã©vidents**

<!--
BST = l'exemple PARFAIT de "structure first" ! Une rÃ¨gle simple gÃ©nÃ¨re des algorithmes puissants.

[LA RÃˆGLE MAGIQUE]
Une seule contrainte : "Gauche < Racine < Droite". C'est tout ! Mais cette rÃ¨gle simple gÃ©nÃ¨re automatiquement :
- Recherche O(log n) : comparez avec racine, allez Ã  gauche ou droite, Ã©liminez la moitiÃ© Ã  chaque Ã©tape
- Insertion O(log n) : suivez la rÃ¨gle, trouvez la position, insÃ©rez
- Suppression : un peu plus complexe mais algorithme standard

[LE MIRACLE DU PARCOURS IN-ORDER]
Parcours in-order = Gauche â†’ Racine â†’ Droite. RÃ©sultat ? Les Ã©lÃ©ments sortent AUTOMATIQUEMENT triÃ©s ! Vous avez construit votre BST en insÃ©rant des Ã©lÃ©ments dans le dÃ©sordre, mais un simple parcours les ressort triÃ©s !

[DÃ‰MONSTRATION MENTALE]
InsÃ©rons : 15, 10, 20, 8, 12, 25, 6
    15
   /  \
  10   20
 / \    \
8   12   25
/
6

Parcours in-order : 6, 8, 10, 12, 15, 20, 25 â†’ TRI AUTOMATIQUE !

Pour les seniors : c'est la base des bases de donnÃ©es indexÃ©es. L'index = BST, les requÃªtes utilisent la propriÃ©tÃ© BST.

Message puissant : UNE contrainte structurelle simple peut rendre des algorithmes complexes (tri, recherche) complÃ¨tement triviaux !
-->

---

# Heaps - PrioritÃ© StructurÃ©e

## PropriÃ©tÃ© de Tas:
- **Min-Heap:** Parent â‰¤ Enfants
- **Max-Heap:** Parent â‰¥ Enfants
- **RÃ©sultat:** Minimum/Maximum accessible en O(1)

<br>

## Applications Naturelles:
- **Files de prioritÃ©:** Urgences hospitaliÃ¨res
- **Algorithme de Dijkstra:** Plus court chemin
- **Tri par tas:** HeapSort en O(n log n)
- **Ordonnancement OS:** Gestion des processus

<br>

âš–ï¸ **Une contrainte de prioritÃ© dans la structure = gestion automatique des prioritÃ©s**

<!--
Heaps = quand vous avez besoin de gÃ©rer des prioritÃ©s efficacement !

[LA PROPRIÃ‰TÃ‰ HEAP]
RÃ¨gle simple : dans un min-heap, parent â‰¤ enfants. ConsÃ©quence magique : le minimum est TOUJOURS Ã  la racine ! Pas besoin de chercher, pas besoin de comparer - c'est structurellement garanti.

[APPLICATIONS RÃ‰ELLES - trÃ¨s concrÃ¨tes]
- HÃ´pital : patients arrivent avec diffÃ©rentes urgences. Min-heap par gravitÃ© â†’ le plus urgent sort automatiquement en premier
- Dijkstra : nÅ“uds avec diffÃ©rentes distances. Min-heap par distance â†’ le plus proche sort automatiquement
- OS : processus avec diffÃ©rentes prioritÃ©s. Heap par prioritÃ© â†’ le plus prioritaire s'exÃ©cute

[ALGORITHME NATUREL]
Insertion : ajoutez Ã  la fin, "remontez" jusqu'Ã  respecter la propriÃ©tÃ© â†’ O(log n)
Extraction : prenez la racine (min garanti), "redescendez" le dernier Ã©lÃ©ment â†’ O(log n)

[COMPARAISON AVEC ALTERNATIVES]
Sans heap : "Quel est le minimum ?" = parcourir tout O(n)
Avec heap : "Quel est le minimum ?" = regarder la racine O(1)

Pour les dÃ©butants : heap = tas organisÃ© oÃ¹ le plus petit/grand est toujours au sommet
Pour les seniors : c'est pourquoi les priority queues utilisent des heaps - structure optimale pour ce besoin

Message : quand vous gÃ©rez des prioritÃ©s, la structure heap rend la gestion automatique et efficace !
-->

---

# Tries - Structure SpÃ©cialisÃ©e pour ChaÃ®nes

## Principe:
- **Arbre de prÃ©fixes:** Chaque chemin = un mot
- **Partage:** PrÃ©fixes communs partagÃ©s
- **EfficacitÃ©:** Recherche en O(longueur du mot)

<br>

## Applications Ã‰videntes:
- **Auto-complÃ©tion:** Suggestions de recherche Google (O(longueur prÃ©fixe))
- **Correcteurs orthographiques:** VÃ©rification de mots
- **Routage IP:** Tables de routage rÃ©seau
- **Compression:** Algorithmes de codage

<br>

ğŸ’¡ **Magie:** La structure reflÃ¨te parfaitement le problÃ¨me Ã  rÃ©soudre !

ğŸ”¤ **Structure spÃ©cialisÃ©e pour un type de donnÃ©es = algorithmes spÃ©cialisÃ©s optimaux**

<!--
Tries = exemple parfait de structure SPÃ‰CIALISÃ‰E pour un problÃ¨me spÃ©cifique !

[PRINCIPE DE BASE]
Trie = arbre oÃ¹ chaque chemin de la racine Ã  une feuille forme un mot. Mots avec prÃ©fixes communs partagent le dÃ©but de chemin. "CAR", "CARD", "CARE" partagent "CAR".

[POURQUOI C'EST GÃ‰NIAL]
Recherche de mot : suivez le chemin lettre par lettre. Temps = longueur du mot, PAS le nombre de mots dans le dictionnaire ! Avec 1 million de mots, chercher "HELLO" = 5 Ã©tapes seulement !

[APPLICATIONS CONCRÃˆTES]
- Google auto-complete : vous tapez "alg", le trie suit Aâ†’Lâ†’G et propose tous les mots qui continuent
- Correcteur : mot mal orthographiÃ© ? Parcourez le trie, trouvez les mots Ã  distance 1-2
- Routage IP : 192.168.1.0 â†’ suivez 1â†’9â†’2â†’1â†’6â†’8... dans le trie des routes

[COMPARAISON]
Sans trie : auto-complÃ©tion = comparer votre prÃ©fixe Ã  TOUS les mots O(nÃ—m)
Avec trie : auto-complÃ©tion = suivre UN chemin O(longueur prÃ©fixe)

[INSIGHT CRUCIAL]
Tries = structure qui REFLÃˆTE parfaitement la nature des chaÃ®nes de caractÃ¨res (sÃ©quences de symboles avec prÃ©fixes communs).

Pour les dÃ©butants : imaginez un dictionnaire organisÃ© par premiÃ¨re lettre, puis deuxiÃ¨me, puis troisiÃ¨me...
Pour les seniors : c'est la base des algorithmes de compression (codes de Huffman), des DNS lookup tables

Message : pour les chaÃ®nes de caractÃ¨res, une structure spÃ©cialisÃ©e (trie) donne des algorithmes beaucoup plus efficaces que les structures gÃ©nÃ©riques !
-->

---

# Graphes - ModÃ©liser les Relations Complexes

## Concepts Fondamentaux:
- **NÅ“uds (Vertices):** EntitÃ©s
- **ArÃªtes (Edges):** Relations entre entitÃ©s
- **OrientÃ©/Non-orientÃ©:** Relations symÃ©triques ou non
- **PondÃ©rÃ©:** Relations avec coÃ»t/distance

<br>

## Abstraction Universelle:
- **RÃ©seaux sociaux:** Personnes + AmitiÃ©s
- **GPS:** Intersections + Routes
- **Internet:** Pages + Liens hypertextes
- **MolÃ©cules:** Atomes + Liaisons chimiques

<br>

ğŸŒ **Le graphe = structure universelle pour modÃ©liser n'importe quelle relation**

<!--
Graphes = LA structure la plus puissante et universelle en informatique !

[CONCEPTS DE BASE]
NÅ“uds = entitÃ©s (choses), 
ArÃªtes = relations entre ces choses. C'est tout ! Mais cette simplicitÃ© peut modÃ©liser TOUT ce qui a des relations.

[EXEMPLES UNIVERSELS - montrer la flexibilitÃ©]
- Facebook : nÅ“uds = personnes, arÃªtes = amitiÃ©s â†’ graphe non-orientÃ©
- Twitter : nÅ“uds = personnes, arÃªtes = "suit" â†’ graphe orientÃ© (A suit B â‰  B suit A)
- GPS : nÅ“uds = intersections, arÃªtes = routes avec distances â†’ graphe pondÃ©rÃ©
- MolÃ©cule : nÅ“uds = atomes, arÃªtes = liaisons chimiques â†’ graphe non-orientÃ©

[PUISSANCE D'ABSTRACTION]
Une fois vos donnÃ©es modÃ©lisÃ©es en graphe, vous dÃ©bloquez TOUS les algorithmes de graphes :
- Plus court chemin (Dijkstra, Floyd-Warshall)
- DÃ©tection de communautÃ©s
- Analyse de centralitÃ©
- DÃ©tection de cycles

[IMPACT CONCRET]
Google PageRank = algorithme sur le graphe du web (pages + liens)
GPS = algorithme de plus court chemin sur graphe routier
Recommandations Netflix = algorithmes sur graphe utilisateurs-films

Pour les dÃ©butants : graphe = rÃ©seau de relations, comme un plan de mÃ©tro
Pour les seniors : c'est pourquoi les bases de donnÃ©es graphes (Neo4j) explosent - pour les donnÃ©es relationnelles complexes

Message : si vos donnÃ©es ont des RELATIONS, modÃ©lisez-les en graphe. Vous dÃ©bloquez immÃ©diatement des dizaines d'algorithmes puissants !

En rÃ©sumÃ©: 
Ce quâ€™il faut retenir : graphe = rÃ©seau de relations.
Si vos donnÃ©es sont connectÃ©es entre elles, pensez graphe.
Et surtout : il existe plein dâ€™algorithmes puissants pour exploiter ces relations !

-->

---

# ReprÃ©sentations - Structure â†’ Algorithmes

## Matrice d'Adjacence
- **Structure:** Tableau 2D (`matrice[i][j]` )
- **Avantage:** VÃ©rifier arÃªte en O(1)
- **InconvÃ©nient:** O(VÂ²) mÃ©moire
- **Usage:** Graphes denses

<br>

## Liste d'Adjacence
- **Structure:** Dict de listes
- **Avantage:** O(V+E) mÃ©moire
- **InconvÃ©nient:** VÃ©rifier arÃªte en O(V)
- **Usage:** Graphes Ã©pars

<br>

ğŸ’¡ **Insight:** Le choix de reprÃ©sentation dÃ©termine quels algorithmes seront efficaces !

ğŸ“Š **MÃªme concept, reprÃ©sentations diffÃ©rentes = algorithmes optimaux diffÃ©rents**

<!--
MÃŠME donnÃ©es (un graphe), mais reprÃ©sentations diffÃ©rentes = algorithmes optimaux diffÃ©rents !

[MATRICE D'ADJACENCE]
Tableau 2D : matrice[i][j] = 1 si arÃªte entre nÅ“ud i et j, 0 sinon.
Avantages : "Y a-t-il une arÃªte entre A et B ?" â†’ matrice[A][B] = rÃ©ponse instantanÃ©e O(1)
InconvÃ©nients : pour 1000 nÅ“uds = 1 million de cases, mÃªme si seulement 10 arÃªtes !

[LISTE D'ADJACENCE] 
Dictionnaire : pour chaque nÅ“ud, liste de ses voisins.
Avantages : seulement les arÃªtes qui existent sont stockÃ©es â†’ Ã©conomie mÃ©moire Ã©norme
InconvÃ©nients : "Y a-t-il une arÃªte entre A et B ?" â†’ parcourir la liste de A jusqu'Ã  trouver B

[ALGORITHMES IMPACTÃ‰S]
- Algorithme dense (beaucoup d'arÃªtes) : matrice plus efficace
- Algorithme Ã©pars (peu d'arÃªtes) : listes plus efficaces
- Parcours de tous les voisins : listes plus efficaces
- VÃ©rifications d'existence frÃ©quentes : matrice plus efficace

[EXEMPLE CONCRET]
Facebook (graphe dense, beaucoup d'amitiÃ©s) â†’ tendance matrice
Internet (graphe Ã©pars, chaque page n'a que quelques liens) â†’ tendance listes

Pour les dÃ©butants : matrice = tableau Excel, listes = carnets d'adresses
Pour les seniors : c'est pourquoi les bases de donnÃ©es ont diffÃ©rents index - mÃªme donnÃ©es, structures diffÃ©rentes pour diffÃ©rents patterns d'accÃ¨s

Message crucial : le choix de reprÃ©sentation n'est PAS un dÃ©tail d'implÃ©mentation - il dÃ©termine quels algorithmes seront efficaces !
-->

---
layout: two-cols-header
---

# Parcours - La Structure Guide l'Exploration

::left::

## ğŸƒâ€â™‚ï¸ BFS (Breadth-First)
- **Structure utilisÃ©e:** Queue
- **Principe:** Explorer niveau par niveau
- **Applications:**
  - Plus court chemin non pondÃ©rÃ©
  - Niveaux dans un rÃ©seau
  - Diffusion d'information

::right::

## ğŸ•³ï¸ DFS (Depth-First)
- **Structure utilisÃ©e:** Stack
- **Principe:** Explorer en profondeur
- **Applications:**
  - DÃ©tection de cycles
  - Composantes connexes
  - Tri topologique

ğŸ§­ **Queue vs Stack dans l'algorithme = exploration complÃ¨tement diffÃ©rente du mÃªme graphe**

<!--
MÃªme graphe, mÃªme donnÃ©es, mais structure auxiliaire diffÃ©rente (Queue vs Stack) = exploration complÃ¨tement diffÃ©rente !

[BFS - BREADTH FIRST]
Structure : Queue (FIFO)
Comportement : explorez tous les voisins du niveau actuel avant de passer au niveau suivant
RÃ©sultat : exploration "en largeur", niveau par niveau

Applications naturelles :
- Plus court chemin NON pondÃ©rÃ© : BFS garantit qu'on trouve le chemin avec le moins d'arÃªtes
- "Ã€ quelle distance sommes-nous ?" : niveaux BFS = distance en nombre de sauts
- Diffusion virale : comment une info se propage niveau par niveau dans un rÃ©seau

[DFS - DEPTH FIRST]
Structure : Stack (LIFO - souvent rÃ©cursion)
Comportement : explorez aussi loin que possible sur une branche avant de revenir
RÃ©sultat : exploration "en profondeur"

Applications naturelles :
- DÃ©tection de cycles : DFS peut dÃ©tecter si on "revient" Ã  un nÅ“ud dÃ©jÃ  visitÃ©
- Composantes connexes : DFS explore complÃ¨tement une composante avant de passer Ã  la suivante
- Tri topologique : ordre de dÃ©pendances (cours prÃ©requis, compilation)

[LA MAGIE]
Regardez : MÃŠME graphe, mais juste changer Queueâ†’Stack change complÃ¨tement l'ordre d'exploration !

DÃ©mo mentale sur un graphe simple :
    A
   / \
  B   C
 /   / \
D   E   F

BFS : A â†’ B,C â†’ D,E,F (niveau par niveau)
DFS : A â†’ B â†’ D, retour B, retour A â†’ C â†’ E, retour C â†’ F (profondeur d'abord)

Message : la structure auxiliaire (Queue vs Stack) dÃ©termine complÃ¨tement l'algorithme d'exploration !
-->

---

# Dijkstra - Quand Structure + PrioritÃ© = Optimal

## Algorithme GÃ©nial:
- **Structure utilisÃ©e:** Graphe pondÃ©rÃ© + Priority Queue (Heap)
- **Principe:** Toujours explorer le nÅ“ud le plus "proche"
- **Garantie:** Plus court chemin optimal
  
<br>

## Applications ConcrÃ¨tes:
- **Google Maps:** ItinÃ©raire optimal
- **RÃ©seaux informatiques:** Routage optimal
- **Jeux vidÃ©o:** IA de navigation
- **Logistique:** Optimisation des livraisons

<br>

ğŸ¯ **Combinaison de structures (Graphe + Heap) = algorithme puissant et Ã©lÃ©gant**

<!-- 
Dijkstra = exemple PARFAIT de combinaison de structures pour crÃ©er un algorithme gÃ©nial !

[STRUCTURES COMBINÃ‰ES]
1. Graphe pondÃ©rÃ© : modÃ©lise le problÃ¨me (nÅ“uds + arÃªtes avec coÃ»ts)
2. Priority Queue (Heap) : gÃ¨re l'efficacitÃ© (toujours traiter le nÅ“ud le plus proche)

[PRINCIPE GÃ‰NIAL]

"Glouton Ã©clairÃ©" : Ã  chaque Ã©tape, explorer le nÅ“ud non-visitÃ© le plus PROCHE de la source. Pourquoi Ã§a marche ? Si j'ai trouvÃ© le chemin le plus court vers A, tout chemin vers B passant par A ne peut que s'allonger !

[ALGORITHME STEP-BY-STEP]
1. Mettez source dans priority queue avec distance 0
2. Extrayez le nÅ“ud le plus proche (heap.pop())
3. Explorez ses voisins, mettez Ã  jour leurs distances
4. Ajoutez les voisins modifiÃ©s dans la priority queue
5. RÃ©pÃ©tez jusqu'Ã  vider la queue

[APPLICATIONS CONCRÃˆTES]

- Google Maps : nÅ“uds = intersections, arÃªtes = routes avec temps de trajet
- Internet : nÅ“uds = routeurs, arÃªtes = liens avec latence
- Jeux : nÅ“uds = positions, arÃªtes = mouvements avec coÃ»t d'Ã©nergie

[POURQUOI C'EST BEAU]

Sans priority queue : "quel est le nÅ“ud le plus proche ?" = parcourir tout O(VÂ²)

Avec heap : "quel est le nÅ“ud le plus proche ?" = heap.pop() O(log V)
ComplexitÃ© totale : O((V + E) log V) au lieu de O(VÂ²)

Pour les dÃ©butants : Dijkstra = GPS qui trouve toujours le chemin le plus rapide
Pour les seniors : base de OSPF, BGP, et tous les protocoles de routage modernes

Message final : COMBINEZ les bonnes structures (graphe pour modÃ©liser + heap pour optimiser) = algorithmes puissants et Ã©lÃ©gants !
-->